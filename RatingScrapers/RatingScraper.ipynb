{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.42'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page No. 1 completed\n",
      "Page No. 2 completed\n",
      "Page No. 3 completed\n",
      "Page No. 4 completed\n",
      "Page No. 5 completed\n",
      "Page No. 6 completed\n",
      "Page No. 7 completed\n",
      "Page No. 8 completed\n",
      "Page No. 9 completed\n",
      "Page No. 10 completed\n",
      "Page No. 11 completed\n",
      "Page No. 12 completed\n",
      "Page No. 13 completed\n",
      "Page No. 14 completed\n",
      "Page No. 15 completed\n",
      "Page No. 16 completed\n",
      "Page No. 17 completed\n",
      "Page No. 18 completed\n",
      "Page No. 19 completed\n",
      "Page No. 20 completed\n",
      "Page No. 21 completed\n",
      "Page No. 22 completed\n",
      "Page No. 23 completed\n",
      "Page No. 24 completed\n",
      "Page No. 25 completed\n",
      "Page No. 26 completed\n",
      "Page No. 27 completed\n",
      "Page No. 28 completed\n",
      "Page No. 29 completed\n",
      "Page No. 30 completed\n",
      "Page No. 31 completed\n",
      "Page No. 32 completed\n",
      "Page No. 33 completed\n",
      "Page No. 34 completed\n",
      "Page No. 35 completed\n",
      "Page No. 36 completed\n",
      "Page No. 37 completed\n",
      "Page No. 38 completed\n",
      "Page No. 39 completed\n",
      "Page No. 40 completed\n",
      "Page No. 41 completed\n",
      "Page No. 42 completed\n",
      "Page No. 43 completed\n",
      "Page No. 44 completed\n",
      "Page No. 45 completed\n",
      "Page No. 46 completed\n",
      "Page No. 47 completed\n",
      "Page No. 48 completed\n",
      "Page No. 49 completed\n",
      "Page No. 50 completed\n",
      "Page No. 51 completed\n",
      "Page No. 52 completed\n",
      "Page No. 53 completed\n",
      "Page No. 54 completed\n",
      "Page No. 55 completed\n",
      "Page No. 56 completed\n",
      "Page No. 57 completed\n",
      "Page No. 58 completed\n",
      "Page No. 59 completed\n",
      "Page No. 60 completed\n",
      "Page No. 61 completed\n",
      "Page No. 62 completed\n",
      "Page No. 63 completed\n",
      "Page No. 64 completed\n",
      "Page No. 65 completed\n",
      "Page No. 66 completed\n",
      "Page No. 67 completed\n",
      "Page No. 68 completed\n",
      "Page No. 69 completed\n",
      "Page No. 70 completed\n",
      "Page No. 71 completed\n",
      "Page No. 72 completed\n",
      "Page No. 73 completed\n",
      "Page No. 74 completed\n",
      "Page No. 75 completed\n",
      "Page No. 76 completed\n",
      "Page No. 77 completed\n",
      "Page No. 78 completed\n",
      "Page No. 79 completed\n",
      "Page No. 80 completed\n",
      "Page No. 81 completed\n",
      "Page No. 82 completed\n",
      "Page No. 83 completed\n",
      "Page No. 84 completed\n",
      "Page No. 85 completed\n",
      "Page No. 86 completed\n",
      "Page No. 87 completed\n",
      "Page No. 88 completed\n",
      "Page No. 89 completed\n",
      "Page No. 90 completed\n",
      "Page No. 91 completed\n",
      "Page No. 92 completed\n",
      "Page No. 93 completed\n",
      "Page No. 94 completed\n",
      "Page No. 95 completed\n",
      "Page No. 96 completed\n",
      "Page No. 97 completed\n",
      "Page No. 98 completed\n",
      "Page No. 99 completed\n"
     ]
    }
   ],
   "source": [
    "source_names = []\n",
    "source_links = []\n",
    "bias_ratings = []\n",
    "community_feedbacks_agree = []\n",
    "community_feedbacks_disagree = []\n",
    "\n",
    "for page in range(1,100):\n",
    "        try:\n",
    "            url = 'https://www.allsides.com/media-bias/ratings?page=' + str(page) + '&field_featured_bias_rating_value=All&field_news_source_type_tid%5B0%5D=1&field_news_source_type_tid%5B1%5D=2&field_news_source_type_tid%5B2%5D=3&field_news_source_type_tid%5B3%5D=4&field_news_source_type_tid%5B4%5D=5&field_news_bias_nid_1%5B1%5D=1&field_news_bias_nid_1%5B2%5D=2&field_news_bias_nid_1%5B3%5D=3&title='\n",
    "            r = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(r.content, 'html.parser')\n",
    "            group_sources = soup.find_all('tr')\n",
    "            # Loop through the elements in the \"group_sources\" list, starting from the second element\n",
    "            # (the first element is a table header and does not contain source names)\n",
    "            for tr in group_sources[1:]:\n",
    "                # Find the first \"a\" element within the current \"tr\" element\n",
    "                a = tr.find_all('a')[0]\n",
    "                # Append the text of the \"a\" element to the \"source_name\" list\n",
    "                source_names.append(a.text)\n",
    "                source_links.append(a['href'])\n",
    "                bias_ratings.append(tr.find_all('img')[0].get('title').split(':')[1][1:])\n",
    "                community_feedbacks_agree.append(int(tr.find('span', class_='agree').text))\n",
    "                community_feedbacks_disagree.append(int(tr.find('span', class_='disagree').text))\n",
    "            print('Page No. %s completed'%str(page))\n",
    "            page += 1\n",
    "        except BaseException as e:\n",
    "                if e != 'KeyboardInterrupt':\n",
    "                    print('Got error when page=%s, error is %s'%(str(page), e))\n",
    "                else:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'source_names': source_names,\n",
    "               'source_links': source_links,\n",
    "               'bias_ratings': bias_ratings,\n",
    "               'community_feedbacks_agree': community_feedbacks_agree,\n",
    "               'community_feedbacks_disagree': community_feedbacks_disagree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result_allratings.csv', encoding='utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bf11db8cbf0c6d1dd913ae8397e141fe3427fbf58842aca45bf3d1002d47eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
